{
  "manifest_id": "manifest_20251228_173214_0ff2b222",
  "experiment_id": "analysis_20251228_173214",
  "created_at": "2025-12-28T17:32:14.776312",
  "system_info": {
    "python_version": "3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 64 bit (AMD64)]",
    "platform": "Windows",
    "platform_version": "10.0.26200",
    "machine": "AMD64",
    "processor": "Intel64 Family 6 Model 142 Stepping 12, GenuineIntel"
  },
  "git_info": {
    "commit_hash": null,
    "branch": null,
    "is_dirty": false,
    "remote_url": null
  },
  "packages": [
    {
      "name": "pandas",
      "version": "2.3.3"
    },
    {
      "name": "numpy",
      "version": "2.3.5"
    },
    {
      "name": "openai",
      "version": "2.14.0"
    },
    {
      "name": "anthropic",
      "version": "0.75.0"
    },
    {
      "name": "google-generativeai",
      "version": "0.8.6"
    },
    {
      "name": "requests",
      "version": "2.32.5"
    },
    {
      "name": "matplotlib",
      "version": "3.10.7"
    },
    {
      "name": "seaborn",
      "version": "0.13.2"
    },
    {
      "name": "scipy",
      "version": "1.16.3"
    },
    {
      "name": "tqdm",
      "version": "4.67.1"
    },
    {
      "name": "hypothesis",
      "version": "6.148.7"
    },
    {
      "name": "pytest",
      "version": "9.0.1"
    },
    {
      "name": "tenacity",
      "version": "9.1.2"
    }
  ],
  "config": {
    "models": {
      "gpt4o": {
        "provider": "openai",
        "model_name": "gpt-4o-mini",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "gpt4": {
        "provider": "openai",
        "model_name": "gpt-4",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "gpt35": {
        "provider": "openai",
        "model_name": "gpt-3.5-turbo",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "claude3_opus": {
        "provider": "anthropic",
        "model_name": "claude-3-opus-20240229",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "claude3_sonnet": {
        "provider": "anthropic",
        "model_name": "claude-3-sonnet-20240229",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "claude3_haiku": {
        "provider": "anthropic",
        "model_name": "claude-3-haiku-20240307",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "gemini_pro": {
        "provider": "google",
        "model_name": "gemini-pro",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "gemini_15_pro": {
        "provider": "google",
        "model_name": "gemini-1.5-pro",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "gemini_15_flash": {
        "provider": "google",
        "model_name": "gemini-1.5-flash",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "llama2_70b": {
        "provider": "hf",
        "model_name": "meta-llama/Llama-2-70b-chat-hf",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "mistral_7b": {
        "provider": "hf",
        "model_name": "mistralai/Mistral-7B-Instruct-v0.2",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "groq_llama3_70b": {
        "provider": "groq",
        "model_name": "llama-3.3-70b-versatile",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "groq_llama3_8b": {
        "provider": "groq",
        "model_name": "llama-3.1-8b-instant",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "groq_qwen3_32b": {
        "provider": "groq",
        "model_name": "qwen/qwen3-32b",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "groq_gpt_oss_120b": {
        "provider": "groq",
        "model_name": "openai/gpt-oss-120b",
        "max_tokens": 1024,
        "temperature": 0.0
      },
      "groq_gpt_oss_20b": {
        "provider": "groq",
        "model_name": "openai/gpt-oss-20b",
        "max_tokens": 1024,
        "temperature": 0.0
      }
    },
    "strategies": {
      "zero_shot": {
        "system_prompt": "You are a helpful assistant. Answer the question directly.",
        "user_template": "{prompt}"
      },
      "cot": {
        "system_prompt": "You are a helpful assistant. Solve the problem step\u2011by\u2011step and give the final answer.",
        "user_template": "{prompt}"
      },
      "self_consistency": {
        "system_prompt": "You are a helpful assistant. Solve the problem step\u2011by\u2011step. Provide **multiple** independent solutions and then give the most common final answer.",
        "user_template": "{prompt}",
        "num_samples": 5
      }
    },
    "retry_config": {
      "max_retries": 3,
      "initial_delay": 1.0,
      "max_delay": 60.0,
      "exponential_base": 2
    },
    "random_seed": 42,
    "custom_config": {
      "analysis_type": "full_report",
      "num_records": 210,
      "models_analyzed": [
        "groq_llama3_70b",
        "groq_llama3_8b",
        "groq_qwen3_32b"
      ],
      "categories_analyzed": []
    }
  },
  "dataset_hash": null,
  "dataset_path": null,
  "notes": "Analysis report generated at 20251228_173214"
}